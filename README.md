# スクレイピングシステムテスト

このリポジトリは、データスクレイピングシステムのテストを目的としています。以下に、このプロジェクトの概要、セットアップ手順、使用方法について説明します。

## プロジェクト概要

このプロジェクトは、ウェブサイトからデータをスクレイピングし、処理および保存するためのシステムを構築することを目的としています。主な機能には、データの取得、データの処理、そしてデータの保存が含まれます。

## ディレクトリ構成

- `main.py`: プロジェクトのエントリーポイント。
- `config/`: 設定ファイルを含むディレクトリ。
  - `settings.py`: プロジェクトの設定を管理します。
  - `logger_config.py`: ログ設定を管理します。
- `src/`: ソースコードを含むディレクトリ。
  - `scraper.py`: データスクレイピングのロジックを実装。
  - `processor.py`: データ処理のロジックを実装。
  - `sheets_handler.py`: データの保存に関するロジックを実装。
  - `models.py`: データモデルを定義。

## セットアップ手順

1. リポジトリをクローンします。
   ```bash
   git clone [リポジトリのURL]
   cd scraping-system-test
   ```

2. 必要なパッケージをインストールします。
   ```bash
   pip install -r requirements.txt
   ```

3. `.env.example` を `.env` にコピーし、必要な環境変数を設定します。

## 使用方法

1. スクリプトを実行してデータをスクレイピングします。
   ```bash
   python main.py
   ```

2. スクレイピングされたデータは、指定されたフォーマットで保存されます。

## 依存関係

- Python 3.12.4
- 必要なパッケージは `requirements.txt` に記載されています。

## 注意事項

- スクレイピング対象のウェブサイトの利用規約を遵守してください。
- 大量のリクエストを送信しないように注意してください。
